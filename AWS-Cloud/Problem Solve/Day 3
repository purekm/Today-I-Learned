Q37
해설:
✅ B. AWS Systems Manager Session Manager
운영 오버헤드 최소화: SSH 키 관리나 배스천 호스트 운영 없이도 원격 접근이 가능.
보안성 향상:
SSH 포트를 열 필요 없음.
키 페어 관리 불필요.
IAM과 SSM 권한 기반으로 접근 제어 가능.
AWS Well-Architected 프레임워크 호환:
자동화 및 보안 우선 접근 방식.
로깅 및 감사 가능 (CloudTrail, SSM 로그).
기본 AWS 서비스만 사용하므로 별도 인프라 비용도 없음.
반복 가능한 방식:
IAM 역할과 SSM Agent 설치만으로 패턴 일관 적용 가능.

❌ 다른 보기들 분석:
A. EC2 직렬 콘솔
제한적 환경에서만 사용 가능 (Amazon Linux 2, Nitro 기반 인스턴스 등).
네트워크 문제 있을 때 디버깅용이지 일반적인 운영 관리에는 부적절.
자동화나 반복적인 운영에는 부적합.

C. 배스천 호스트 + SSH 키
운영 오버헤드 큼: 키 관리, 호스트 유지보수 필요.
보안상 취약점 증가: 퍼블릭 서브넷에 SSH 포트 열림, 사용자 접근 통제 복잡.
Well-Architected 프레임워크의 ‘보안’ 원칙에 위배 가능.

D. Site-to-Site VPN + 온프레미스 SSH
설정 복잡, VPN 인프라 구축 필요.
온프레미스 의존도 증가, 클라우드 네이티브 아님.
운영 오버헤드 큼, 반복적이고 확장 가능한 구조 아님.

Q38
정답: C. S3 버킷 앞에 Amazon CloudFront 배포를 추가합니다. CloudFront 배포를 가리키도록 Route 53 항목을 편집합니다.
📌 해설:
✅ C. CloudFront + S3
CloudFront는 전 세계 엣지 로케이션을 통해 콘텐츠를 캐싱하여 사용자에게 더 가까운 위치에서 빠르게 정적 파일 제공.
정적 웹 사이트와 전 세계 트래픽 최적화 조합에 가장 적합한 솔루션.
비용 효율성:
데이터 전송 비용이 S3보다 저렴해지는 경우도 많음.
사용량 기반 과금 (낮은 트래픽은 저렴하게, 높은 트래픽은 캐시율 향상으로 비용 효율적).
S3 + CloudFront는 AWS 공식 문서에서도 정적 웹사이트에 권장되는 아키텍처입니다.
Route 53은 CloudFront 도메인을 가리키도록 설정하면 됨.
=>웹사이트를 입력했을 때, 가장 가까운 리전에 있는 S3 액세스

❌ 다른 보기들 분석:
A. S3 버킷을 모든 리전에 복제 + 지리적 위치 라우팅
비용 비효율적:
S3 버킷 복제 비용 + 중복 저장 + 관리 복잡성.
운영 부담 증가:
버킷 간 동기화 관리 필요.
CloudFront로 해결 가능한 문제에 과도한 리소스 사용.

B. Global Accelerator + S3
Global Accelerator는 ALB, NLB, EC2 등과 연동 가능,
정적 웹사이트 S3에는 직접 연결 불가.
또한 S3는 IP 주소 기반으로 연결되지 않음 → Global Accelerator의 IP와 호환되지 않음.
비용도 높음 (고정 요금 + 사용량 기반).

D. S3 Transfer Acceleration
S3에 업로드하는 사용자(쓰기)에 최적화된 서비스.
다운로드(웹사이트 트래픽)에는 효과 미미함.
CloudFront가 동일한 기능 + 더 많은 최적화 제공.

Q39
정답: A. 스토리지 유형을 프로비저닝된 IOPS SSD로 변경합니다.

📌 해설:
현재 상황:
천만 개 이상의 행
2TB 범용 SSD (gp2) 사용 중
수백만 건의 업데이트 발생 (I/O 집약적 작업)
일부 삽입 작업이 10초 이상 지연
이러한 상황은 스토리지의 IOPS 한계로 인해 발생할 가능성이 매우 높습니다.
범용 SSD -> EBS 등급 생각해라

✅ A. 프로비저닝된 IOPS SSD (io1 또는 io2)
지속적이고 예측 가능한 고성능 I/O를 제공.
gp2는 스토리지 용량에 따라 IOPS가 결정되며, 과도한 쓰기 시 성능 한계에 도달.
io1/io2는 원하는 IOPS를 명시적으로 설정할 수 있어 대규모 트랜잭션에 적합.
특히 쓰기 작업이 집중되는 워크로드에 효과적.

❌ 다른 보기들 분석:
B. 메모리 최적화 인스턴스 (ex. r5, r6)
읽기 캐시, 쿼리 처리에 도움이 되지만, 저장소 성능 병목과는 직접적 연관 없음.
삽입 작업이 느린 건 디스크 IOPS 부족이 원인 → 해결 불가.

C. 버스트 가능한 성능 인스턴스 (ex. t3, t4g)
일정량 CPU/네트워크 성능만 제공, CPU 크레딧 기반.
고부하 또는 지속적인 부하에 부적합.
현재 같은 지속적인 쓰기 작업이 많은 워크로드에는 매우 부적절.

D. 읽기 전용 복제본 추가
읽기 처리 분산 가능하지만, 삽입/쓰기 성능에는 전혀 영향 없음.
오히려 복제 지연으로 쓰기 성능에 영향 줄 수도 있음.
쓰기 병목은 본 인스턴스의 스토리지 문제이므로 해결책 아님.

Q40
왜 A가 최적의 선택인가?
🔹 Kinesis Data Firehose
운영 부담 거의 없음 (서버리스)
실시간으로 데이터 수집 → 자동으로 S3에 저장
배치 크기나 시간 기준으로 자동 전송 가능
내결함성/확장성 내장, 고가용성
🔹 Amazon S3
저렴한 저장소, 실시간 분석도 가능 (Athena, Glue 등과 연계)
수명주기 정책으로 Glacier 전환 설정 가능 → 아카이빙
🔹 14일 분석 + 장기 저장 정책 구현 가능
S3 표준 스토리지에서 14일간 유지
이후 자동으로 S3 Glacier로 전환되어 장기 보관 비용 절감

❌ 다른 보기들 분석:
B. EC2 + S3 + 수명주기
EC2 인프라 직접 관리 필요 → 운영 부담 많음
고가용성, 확장성 직접 구성해야 함
비용 및 복잡도 ↑

C. Kinesis Data Firehose → OpenSearch
OpenSearch는 실시간 검색용이지만, 비용이 매우 높음
장기 보관은 스냅샷 수동 관리 필요 → 운영 효율성 낮음
고비용 + 아카이빙 불편 → 요구사항과 부합 X

D. SQS 사용 + 메시지 수명 추적 + S3 저장
SQS는 일시적 메시징에 적합, 장기 저장/분석용 아님
메시지를 직접 체크하고 S3로 전송해야 함 → 운영 부담 큼
비용 효율성 낮고, 불필요하게 복잡


Q41
현재 문제:
EC2 인스턴스에서 SaaS 데이터 수신 → S3 업로드 → 알림 전송 모두 처리 중.
즉, 모든 처리가 한 곳(EC2)에 집중되어 과부하, 성능 저하 발생.

✅ B. AppFlow + S3 + SNS (서버리스 기반 솔루션)
Amazon AppFlow는 SaaS ↔ AWS 간 데이터 전송을 자동화하는 완전관리형 서비스.
Salesforce, Zendesk, Google Analytics 등 주요 SaaS와 통합 가능.
EC2 없이 데이터 직접 수집 가능.
S3 이벤트 알림 + SNS를 활용하면,
파일 업로드 후 자동으로 사용자 알림 전송 가능.
전체 아키텍처가 서버리스이기 때문에:
운영 오버헤드 없음, 성능 병목 없음, 자동 확장됨.

❌ 다른 보기들 분석:
A. EC2 Auto Scaling + SNS
Auto Scaling이 성능을 일정 부분 개선할 수 있지만,
EC2 사용 자체가 운영 오버헤드 유발.
SaaS → EC2 → S3 → SNS로 여전히 중간단계 많음 → 비효율.

C. EventBridge 규칙 + S3 업로드 + SNS
SaaS에서 직접 EventBridge로 출력을 보내는 건 일반적으로 어려움.
대부분 SaaS는 AppFlow 같은 통합 서비스 필요.
구성 복잡 + 실현 난이도 높음.

D. ECS(Docker 컨테이너) + CloudWatch Container Insights + SNS
EC2 대신 컨테이너화로 어느 정도 성능 분산 가능하나,
컨테이너 운영 및 모니터링 오버헤드 여전히 존재.
또한 Container Insights는 알림 트리거 도구가 아님 → 오용

Q42
상황 요약
EC2 인스턴스 여러 개가 **여러 가용 영역(AZ)**에서 실행 중
EC2 간 통신은 없음
EC2는 Amazon S3와만 통신 (이미지 다운로드 & 업로드)
S3 접속 시 NAT 게이트웨이 사용 중

✅ C. Gateway VPC 엔드포인트 for Amazon S3
S3 통신을 **인터넷을 거치지 않고 AWS 내부 네트워크(VPC 엔드포인트)**로 처리
NAT 게이트웨이 불필요, 요금 절감 가능
동일 리전에 있는 S3와의 통신은 무료
고가용성, 운영 오버헤드 없음, 완전관리형

❌ 다른 보기 분석:
A. 각 AZ마다 NAT 게이트웨이 추가
NAT 게이트웨이는 시간당 요금 + 데이터 전송 요금이 발생
AZ 간 NAT 트래픽 요금은 줄일 수 있지만, 총 비용은 오히려 증가할 수 있음

B. NAT 인스턴스 사용
운영 복잡도↑ (인스턴스 관리, 보안 패치, 용량 모니터링)
요금 절감 가능성은 있지만, 안정성과 유지 보수 부담 큼
AWS에서도 현재는 NAT 인스턴스보다 VPC 엔드포인트를 권장

D. EC2 전용 호스트 사용
이는 라이선싱 또는 하드웨어 격리가 필요한 경우에 사용
데이터 전송 요금과 무관, 오히려 비용 증가 요소

Q43
 정답: B. 새 AWS Direct Connect 연결을 설정하고 이 새 연결을 통해 백업 트래픽을 직접 연결합니다.
📌 해설:
🔹 AWS Direct Connect
온프레미스 ↔ AWS 간 전용 네트워크 연결을 제공
인터넷을 거치지 않음 → 인터넷 대역폭에 영향 없음
S3에 대한 안정적이고 고속 전송 가능
전송 시간 예측 가능 → 시간 민감한 백업에 적합
장기적이고 비용 효율적 (트래픽 많을수록 유리)

❌ 다른 보기 분석:
A. VPN 연결 + VPC 엔드포인트
VPN은 인터넷을 통해 동작하므로, 인터넷 대역폭 문제를 해결하지 못함
VPC 엔드포인트는 EC2 → S3 트래픽 최적화용이지, 온프레미스 트래픽과 무관

C. Snowball을 매일 주문
Snowball은 오프라인 데이터 전송용, 일시적 대안에 적합
매일 주문하고 반환하는 건 비현실적 + 비효율적
지속적인 백업에 부적합

D. S3 서비스 제한 상향 요청
S3는 기본적으로 데이터 수신량에 제한이 없음 (스루풋은 거의 무제한)
이 문제는 AWS 측 제한이 아니라, 인터넷 대역폭 문제이므로 무관한 요청

Q44.
✅ A. 버전 관리(Versioning) 활성화
우발적인 삭제나 덮어쓰기를 방지하는 가장 기본적이고 중요한 기능.
객체가 삭제되거나 덮어써도 이전 버전을 보존함.
복구가 가능하기 때문에 실수로 인한 데이터 손실 방지에 매우 효과적.

✅ B. MFA 삭제(MFA Delete) 활성화
객체 버전 삭제 또는 버전 관리 비활성화 시 MFA 인증을 요구.
실수 혹은 악의적인 삭제로부터 데이터를 보호하는 추가적인 보안 계층.
루트 사용자만 설정 가능하며, CLI를 통해 활성화해야 함.

❌ 다른 선택지 설명:
C. 버킷 정책 생성
액세스 제어나 권한 제한에는 도움이 되지만,
버전 복구나 삭제 방지 기능은 직접 제공하지 않음.

D. 기본 암호화 활성화
**데이터 보호(암호화)**에는 유효하지만,
삭제 방지와는 무관.

E. 수명 주기 정책 생성
오히려 데이터를 자동으로 삭제하거나 아카이브하는 데 사용됨.
우발적 삭제 방지 목적에는 부적절.

Q45
해결 방안:
✅ B. SQS 대기열을 생성하고 SNS 주제를 구독
SNS → SQS 구조로 바꾸면,
메시지를 보존할 수 있고,
네트워크나 Lambda 오류 발생 시에도 메시지가 사라지지 않음.
내구성 보장: SQS는 메시지를 일정 기간 보존함 (최대 14일).

✅ E. Lambda 함수를 SQS 대기열 소비자로 등록
Lambda가 SQS에서 메시지를 폴링하여 이벤트를 받아 처리.
실패한 경우에는 자동 재시도, **DLQ(Dead Letter Queue)**로도 연계 가능.
모든 데이터 처리 보장을 위한 구조 완성.

❌ 오답 해설:
A. 여러 AZ에 Lambda 배포
Lambda는 기본적으로 리전 단위의 고가용성 제공
→ 직접 AZ 배포 개념 없음, 무관한 선택지

C. CPU와 메모리 증가
성능은 증가할 수 있으나, 실패로 인한 데이터 유실과는 무관
네트워크 이슈나 실패에 대한 보장/재처리 기능 없음

D. 프로비저닝 처리량
Lambda는 서버리스이며, 트리거 기반 실행
→ 프로비저닝 처리량 개념이 없음 (단, Provisioned Concurrency는 cold start와 관련)

Q46 
정답:
B. Amazon S3 버킷을 보안 전송 지점으로 사용합니다. Amazon Macie를 사용하여 버킷의 객체를 스캔합니다. 객체에 PII가 포함된 경우 Amazon SNS를 사용하여 관리자에게 알림을 트리거합니다.

📌 해설:
✅ Amazon Macie
Amazon S3에서 PII, 신용카드 번호, 이름, 주민등록번호 등 민감한 데이터 탐지를 위한
완전관리형 서비스.
머신러닝 기반으로 자동으로 민감 정보 스캔 가능.
서버리스 구조로 작동하며, 대용량 파일도 지원 (200GB 이상 파일 처리 가능).
SNS와 통합하여 자동 알림 전송 가능.

✅ 이 솔루션의 장점:
요소	효과
S3 버킷 사용	SFTP 대상 스토리지로 안전하고 신뢰성 높은 스토리지
Amazon Macie	민감 정보(Personal Identifiable Info) 자동 탐지
Amazon SNS	관리자에게 자동 알림 전송 가능
자동화	수작업 없이 탐지 + 경고 전 과정을 자동화
❌ 오답 분석:
A. Amazon Inspector 사용
❌ Amazon Inspector는 EC2, Lambda, 컨테이너 보안 검사 도구
→ S3 객체의 민감정보(Personal Data)를 검사할 수 없음.

C, D. 사용자 정의 Lambda 스캐닝
❌ 직접 구현해야 하므로 개발 노력 매우 큼 (문제 조건 위배)
❌ 대용량(200GB) 파일 처리 어려움 → Lambda 메모리/타임아웃 제한
❌ S3 수명 주기 정책은 시간 기반 동작이며, 이벤트 기반 삭제 트리거 불가

Q47
해설:
🔹 온디맨드 용량 예약 (On-Demand Capacity Reservation)
EC2 용량을 미리 예약해 두어, 필요한 시점에 항상 사용할 수 있도록 보장하는 기능
온디맨드 인스턴스 가격으로 과금되며, 예약만으로는 요금이 발생하지 않음
다음과 같은 경우에 적합:
특정 AZ, 인스턴스 타입, 수량 등을 명시해야 함
단기간 동안 용량 보장 필요
예약 인스턴스의 장기 약정 없이 유연하게 사용하고 싶을 때

❌ 다른 보기 분석:
A. 필요한 리전을 지정하는 예약 인스턴스 구매
❌ 예약 인스턴스는 비용 절감 옵션이지, 용량을 보장하지는 않음
❌ AZ 단위 지정 불가 (기본적으로 Region 단위 예약)

B. 필요한 지역을 지정하는 온디맨드 용량 예약
❌ 리전 단위 예약은 불가능. 온디맨드 용량 예약은 AZ 단위로 지정해야 함
→ 3개 AZ 지정 불가능하므로 조건 불충족

C. 리전과 3개 AZ 지정하는 예약 인스턴스
❌ 예약 인스턴스는 용량 예약 기능이 없음
❌ 비용 절감만 제공, 용량 보장 불가


Q48
해설:
🔹 현재 문제점
EC2 인스턴스 스토어는 인스턴스가 종료되거나 실패하면 데이터가 영구적으로 사라짐.
따라서 내구성도 낮고, 가용성도 낮음.

✅ D. Amazon EFS
다중 AZ에서 자동으로 데이터를 복제 → 고가용성
완전관리형, 탄력적 파일 스토리지 → 용량 자동 조절
EC2 여러 인스턴스에서 동시에 접근 가능
항목 카탈로그처럼 파일 기반 데이터에 적합
데이터는 내구적이고, 지속성 보장됨

❌ 오답 해설:
A. Redis용 Amazon ElastiCache
Redis는 메모리 기반 캐시 시스템 → 내구성 없음
재부팅하거나 장애 발생 시 데이터 손실 가능
항목 카탈로그 저장소로는 부적절 (단기 캐싱용)

B. 더 큰 인스턴스 스토어
저장공간은 커지지만, 인스턴스 스토어 자체는 휘발성
인스턴스 재시작/종료 시 데이터 손실 여전

C. Amazon S3 Glacier Deep Archive
장기 아카이빙 용도로 적합 (보통 복구에 수 시간 소요)
항목 카탈로그처럼 자주 접근해야 하는 데이터에는 부적절

Q49
 왜 B가 최적의 솔루션인가?
✅ S3 Intelligent-Tiering
1년 이내 무작위 액세스에 최적화된 비용 효율적 스토리지
자주 액세스 ↔ 드물게 액세스 계층 자동 전환 → 비용 최적화
빠른 검색 성능 유지, 자동화되어 운영 부담 없음

✅ 1년 이후 → S3 Glacier Flexible Retrieval
저렴한 장기 보관용 스토리지
복구 시간 수 분 ~ 수 시간 허용 가능
비용 절감 극대화

✅ Athena 또는 S3 Select
Amazon Athena: S3에 있는 데이터를 SQL로 쿼리
S3 Glacier Select: 아카이브된 데이터에서 필요한 부분만 추출 가능 → 불필요한 전체 복원 없이도 검색 가능

❌ 다른 보기들 해설:
A. S3 Glacier Instant Retrieval + 태그 검색
Instant Retrieval은 지속적 빠른 액세스를 위한 Glacier 계층이지만 비용이 높음
모든 파일을 이 계층에 넣는 건 과잉 설계 + 과다 비용

C. S3 Standard → Glacier Instant Retrieval
비슷하지만, Glacier Instant Retrieval은 여전히 빠른 접근을 위한 고비용 계층
파일 접근 빈도가 낮아지는 1년 이후에 굳이 빠른 복구 필요 없음
비용 측면에서 Glacier Flexible Retrieval이 더 적절

D. S3 Standard → Glacier Deep Archive + RDS 메타데이터
Deep Archive는 복구에 최대 12~48시간 소요
사용자 쿼리 요청 시 너무 지연이 심함
RDS로 검색 메타데이터 관리하는 것은 운영 복잡성 증가

Q50
조건	설명
🖥️ EC2 환경	1,000개의 Linux 인스턴스, 프로덕션 환경
🔧 대상	타사 소프트웨어의 보안 취약점 패치
⏱️ 요구사항	즉시 적용, 자동화된 일괄 처리
❌ 대상 아님	일반 OS 패치나 예약된 유지보수 아님
✅ D. AWS Systems Manager Run Command
EC2 인스턴스에 직접 명령어를 실행할 수 있는 강력한 기능
타사 소프트웨어 설치, 업데이트, 패치 등 사용자 정의 작업 수행 가능
대상 인스턴스를 태그, 인스턴스 ID 등으로 지정 가능
즉시 실행 가능하며, 실패 인스턴스 로그 확인 및 재시도 가능
운영 체제, 패치 도구와 무관하게 스크립트 기반으로 유연한 처리 가능

❌ 오답 해설:
A. AWS Lambda
Lambda는 EC2 인스턴스 내에서 실행되지 않음
EC2 내부에 접근하려면 복잡한 SSH 설정 필요 → 부적합
Lambda는 짧은 작업(최대 15분) + 서버리스 작업용 → 대규모 EC2 작업에는 적합하지 않음

B. Patch Manager
AWS에서 관리하는 운영체제(OS) 및 관련 소프트웨어에 대한 패치만 가능
타사 소프트웨어는 지원하지 않음 → 요건 불충족

C. 유지 관리 기간(Maintenance Window)
특정 시간대에 패치 또는 명령을 실행하는 예약 도구
"즉시 실행"이 필요한 보안 위협 상황에는 적합하지 않음

Q51
REST API로부터 주문 배송 통계를 수집
데이터를 HTML 형식 보고서로 변환
매일 아침 여러 이메일 주소로 자동 전송
→ 자동화된, 형식화된, 이메일 기반 보고 시스템 필요

✅ D. Lambda + EventBridge 예약 이벤트
**EventBridge (CloudWatch Events)**를 사용하면 매일 아침 스케줄링 가능
Lambda 함수를 호출하여:
API에서 배송 통계를 요청
HTML 형식으로 가공
이메일 발송 준비
→ 데이터 추출 & 보고서 생성 자동화의 핵심

✅ B. Amazon SES로 이메일 발송
Amazon SES는 AWS의 이메일 전송 서비스
Lambda 함수에서 HTML 보고서를 SES를 통해 이메일로 전송
여러 수신자 지원, 신뢰도 높고 비용 효율적

❌ 오답 해설
A. Kinesis Data Firehose
스트리밍 데이터 처리용 → 실시간 로그나 이벤트 데이터에 적합
이번 워크로드는 정기 배치 기반 보고서 생성이므로 부적합

C. Glue 작업 + EventBridge
AWS Glue는 ETL 또는 대규모 데이터 처리에 적합
이번 경우는 단순한 API 호출 및 HTML 보고서 생성이므로 Glue는 과도하고 비용 비효율적

E. S3 + SNS
S3는 보고서 저장소로는 쓸 수 있지만,
보고서 작성 트리거나 이메일 전송 기능 자체는 없음
SNS는 이메일 발송에 쓰이긴 하지만 HTML 포맷/형식화된 메시지 전송에는 SES가 더 적절

Q52
✅ Amazon EFS (Elastic File System)
파일 시스템 구조 지원 (POSIX-compliant)
수백 TB까지 자동 확장
다중 AZ 고가용성 내장
여러 EC2 인스턴스에서 동시에 마운트 가능
서버리스 방식으로 운영 오버헤드 거의 없음
비용은 사용한 만큼만 청구

✅ EC2 Auto Scaling Group + 다중 AZ
컴퓨팅 리소스를 필요에 따라 자동으로 확장/축소
AZ 간 분산으로 고가용성 확보
EFS는 여러 인스턴스에서 공유 가능 → 유연한 확장성

❌ 오답 분석
A. ECS + Amazon S3
S3는 객체 스토리지, 파일 시스템이 아님
POSIX 파일 구조 요구 조건을 충족하지 못함
S3는 파일 단위 업로드/다운로드만 가능 (랜덤 접근 불가)

B. EKS + EBS
EBS는 EC2 인스턴스 1개에 종속됨
Kubernetes 환경에서 EBS는 pod 단위로 연결되며 확장성과 고가용성 제한
운영 복잡성 + EBS는 자동 확장 X

D. EC2 + EBS
EBS는 AZ 단위 스토리지, 고가용성 보장 X
확장성이 제한되고, 인스턴스간 공유 불가
수백 TB 수준이면 볼륨 관리 복잡도↑

Q53
 C가 정답인 이유:
✅ S3 Object Lock - 규정 준수(Compliance) 모드
가장 강력한 삭제 방지 기능
루트 사용자조차 설정된 보존 기간 동안 객체를 삭제하거나 덮어쓸 수 없음
**규제 요건(예: 금융, 회계 기록)**을 만족하기 위한 기능

✅ 수명 주기 정책
1년간은 S3 Standard에 저장 (즉시 접근 가능)
이후 자동으로 S3 Glacier Deep Archive로 이전 → 장기 보관 비용 절감

✅ Glacier Deep Archive
장기 보관에 가장 저렴한 S3 스토리지 클래스
복원 시간이 몇 시간 소요되지만, 이 경우 문제 없음 (1년 이후 드물게 접근)

❌ 오답 해설:
A. 10년 동안 S3 Glacier + 접근 제어 정책
❌ **접근 제어(IAM, 버킷 정책)**만으로는 루트 사용자 삭제 차단 불가
❌ Object Lock 규정 준수 모드만이 완전한 삭제 방지 보장

B. Intelligent-Tiering + IAM 정책
❌ 삭제 방지 요건 충족 불가 (루트는 우회 가능)
❌ 비용 비효율적: Intelligent-Tiering은 주기적으로 접근 여부 평가 → 오버헤드 증가

D. One Zone-IA + Object Lock (거버넌스 모드)
❌ 거버넌스 모드는 관리자 override 가능
❌ One Zone-IA는 복원력 낮음 (AZ 1개) → 요구된 최대 복원력 미충족

Q54
Amazon FSx for Windows File Server
완전관리형 Windows 파일 공유 서비스
SMB 프로토콜 지원 → 기존 Windows 사용자들의 접근 방식 유지 가능
Active Directory 통합, ACL 지원 → 기존 보안 설정 유지
다중 AZ 복제 및 백업 자동화 → 고가용성 및 내구성 충족
마이그레이션 간편: 기존 EC2 파일 공유에서 FSx로 데이터 이전 가능

❌ 다른 보기 해설:
A. Amazon S3 + IAM 인증
❌ SMB 파일 공유 방식이 아님 → 사용자는 기존처럼 탐색기에서 드라이브로 접근 불가
❌ IAM 권한 구성 복잡, 탐색기 연동 UX 부적합

B. S3 파일 게이트웨이 + EC2 마운트
❌ 로컬 캐시 기반으로 작동하며 완전한 Windows 파일 서버 대체가 아님
❌ 고가용성 및 NTFS 권한 완전 지원 안 됨

권한, 성능, 호환성 문제 있음

D. Amazon EFS
❌ EFS는 Linux 기반 NFS를 지원하는 파일 시스템
❌ Windows에서 직접 마운트 불가능, SMB와 비호환

Q55
왜 C가 맞는가?
EC2 인스턴스가 RDS에 접근하기 위해서는:
RDS의 보안 그룹에서 해당 인스턴스의 보안 그룹을 신뢰해야 함
보안 그룹 간 참조는 다음과 같이 설정:

RDS 보안 그룹 인바운드 규칙:
- 소스: EC2 인스턴스의 보안 그룹
- 포트: 3306 (MySQL), 5432 (PostgreSQL) 등

❌ 오답 해설:
A. 퍼블릭 서브넷에 대한 경로 제외
❌ 서브넷 간 통신은 라우팅이 아닌 보안 그룹/ACL이 주된 제어 수단
❌ 퍼블릭 서브넷이라고 해서 DB 접근을 차단하는 방식 아님

B. 퍼블릭 서브넷 인스턴스의 보안 그룹을 차단
❌ "거부(Deny)"는 보안 그룹에 존재하지 않음
보안 그룹은 허용만 가능, 명시적 거부는 지원하지 않음
→ 이 옵션은 기술적으로 잘못된 설명

D. 피어링 연결 생성
❌ 모든 서브넷이 같은 VPC 내에 존재하고 있으며,
VPC 내 통신에 피어링은 불필요
→ 과도한 설정

